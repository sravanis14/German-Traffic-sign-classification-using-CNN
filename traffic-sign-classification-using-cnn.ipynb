{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8354921,"sourceType":"datasetVersion","datasetId":4964419}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\" \nMulti-class classification\n\"\"\"\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/german-traffic-sign-recognition-dataset/german_trafficsign/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path + '/Train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = {\n                        0 : 'speed limit 20(kmph)', \n                        1 : 'speed limit 30(kmph)', \n                        2 : 'speed limit 50(kmph)', \n                        3 : 'speed limit 60(kmph)', \n                        4 : 'speed limit 70(kmph)', \n                        5 : 'speed limit 80(kmph)', \n                        6 : 'restriction ends 80(kmph)',\n                        7 : 'speed limit 100(kmph)', \n                        8 : 'speed limit 120(kmph)',\n                        9 : 'no overtaking', \n                        10 : 'no overtaking (trucks)', \n                        11 : 'priority at next intersection', \n                        12 : 'priority road', \n                        13 : 'give way', \n                        14 : 'stop', \n                        15 : 'no traffic both ways', \n                        16 : 'no trucks', \n                        17 : 'no entry', \n                        18 : 'danger', \n                        19 : 'bend left', \n                        20 : 'bend right', \n                        21 : 'bend', \n                        22 : 'uneven road', \n                        23 : 'slippery road', \n                        24 : 'road narrows', \n                        25 : 'construction', \n                        26 : 'traffic signal', \n                        27 : 'pedestrian crossing', \n                        28 : 'school crossing', \n                        29 : 'cycles crossing', \n                        30 : 'snow', \n                        31 : 'animals',\n                        32 : 'restriction ends',\n                        33 : 'go right',\n                        34 : 'go left', \n                        35 : 'go straight',\n                        36 : 'go right or straight', \n                        37 : 'go left or straight', \n                        38 : 'keep right',\n                        39 : 'keep left', \n                        40 : 'roundabout',\n                        41 : 'restriction ends (overtaking)',\n                        42 : 'restriction ends (overtaking (trucks))'\n                      }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df['class_name'] = np.nan\n#df.loc[df.ClassId.isin(prohibitory), \"class_name\"] = 'Prohibitory'\n#df.loc[df.ClassId.isin(mandatory), \"class_name\"] = 'Mandatory'\n#df.loc[df.ClassId.isin(danger), \"class_name\"] = 'Danger'\n#df.loc[df.ClassId.isin(other), \"class_name\"] = 'Other'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size =0.2, shuffle = True, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 0.001\nBATCH_SIZE = 32\nEPOCHS = 10\nIMG_SIZE = 32\nDEVICE = 'cuda'\n#MODEL_NAME = 'efficient_b0'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = df.iloc[80]\nimg_path = path + row.Path\nlabel = row.ClassId\n\nimage = cv2.imread(img_path)\nimage = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n\nprint(image.shape)\nplt.imshow(image)\nplt.title(label)\nplt.axis('off')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = df.iloc[800]\nimg_path = path + row.Path\nlabel = row.ClassId\n\nimage = cv2.imread(img_path)\nimage = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n\nprint(image.shape)\nplt.imshow(image)\nplt.title(label)\nplt.axis('off')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms as T\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_augs():\n    return A.Compose([\n              A.Resize(IMG_SIZE,IMG_SIZE),\n              A.HorizontalFlip(p=0.5),\n              \n                 ])\n\ndef get_valid_augs():\n    return A.Compose([\n              A.Resize(IMG_SIZE,IMG_SIZE)\n\n                 ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrafficDataset(Dataset):\n  def __init__(self,df,transforms = None):\n    self.df = df\n    self.transforms = transforms\n\n  def __len__(self):\n    return len(self.df)\n\n  def __getitem__(self,idx):\n\n    row = self.df.iloc[idx]\n    image_path = row.Path\n    labels = row.ClassId\n\n    image = cv2.imread(path + image_path)\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n\n    if self.transforms:\n        data = self.transforms(image = image, labels = labels) # dictionary image as key and mask as value\n        image = data['image']\n        labels = data['labels']\n\n    # convert (h,w,c) to (c,h,w)\n    image = np.transpose(image,(2,0,1)).astype('float32')\n    image = torch.Tensor(image) / 255.0\n\n    return image , labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = TrafficDataset(train_df,get_train_augs())\nvalidset = TrafficDataset(valid_df,get_valid_augs())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Size of Trainset : {len(trainset)}\")\nprint(f\"Size of Validset : {len(validset)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 12\nimage,labels = trainset[idx]\nimage = np.transpose(image,(1,2,0))\nplt.imshow(image)\nplt.suptitle(labels)\nplt.title(id2label[labels])\nplt.axis('off')\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainloader = DataLoader(trainset,batch_size = BATCH_SIZE,shuffle = True)\nvalidloader = DataLoader(validset,batch_size = BATCH_SIZE)\nprint(\"Total number of batches in trainloader :\", len(trainloader))\nprint(f\"Total no. of batches in validloader :{len(validloader)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image , label in trainloader:\n    break\n\nprint(f\" Shape of image: {image.shape}\")\nprint(f\" Shape of label: {label.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ClassifierModel(nn.Module):\n\n    def __init__(self,num_classes,dropout) :\n        super(ClassifierModel,self).__init__()\n        self.num_classes = num_classes\n        self.dropout = dropout\n        self.features = nn.Sequential(\n                        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3,  padding='same'),\n                        nn.ReLU(inplace = True),\n                        nn.Conv2d(in_channels = 64,out_channels = 64, kernel_size =3, padding ='same'),\n                        nn.ReLU(inplace = True),\n                        nn.MaxPool2d((2,2),stride = (2,2)),\n                        \n                        nn.Conv2d(in_channels=64, out_channels=64*2, kernel_size=3,padding='same'),\n                        nn.ReLU(inplace = True),\n                        nn.Conv2d(in_channels =128, out_channels = 64*2, kernel_size =3, padding ='same'),\n                        nn.ReLU(inplace = True),\n                        nn.MaxPool2d((2,2),stride = (2,2)),\n            \n                        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same'),\n                        nn.ReLU(inplace = True),\n                        nn.Conv2d(in_channels =256, out_channels = 256, kernel_size =3, padding ='same'),\n                        nn.ReLU(inplace = True),\n                        nn.Conv2d(in_channels =256, out_channels = 256, kernel_size =3, padding ='same'),\n                        nn.ReLU(inplace = True),\n                        nn.MaxPool2d((2,2),stride = (2,2)),\n                        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 4 * 4, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=self.dropout),\n            nn.Linear(1024, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=self.dropout),\n            nn.Linear(1024, self.num_classes),)\n        #self.eff_net = timm.create_model('efficientnet_b0',pretrained = True,num_classes = 4)\n    def forward(self,images,labels = None):\n        #logits = self.eff_net(images)\n        x = self.features(images)\n        h = x.view(x.shape[0], -1)\n        logits = self.classifier(h)\n        if labels !=None:\n            loss = nn.CrossEntropyLoss()(logits,labels)\n            return logits,loss\n        return logits","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ClassifierModel(43,0.5)\nmodel.to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_accuracy(y_pred,y_true):\n    top_pred = y_pred.argmax(1, keepdim = True)\n    correct_pred = top_pred.eq(y_true.view_as(top_pred)).sum()\n    acc = correct_pred.float() / y_true.shape[0]\n    return acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(model,dataloader,optimizer,current_epo):\n    model.train()\n    total_loss =0.0\n    total_acc =0.0\n    tk =tqdm(dataloader,desc = \"EPOCH\" + \"[Train]\"+str(current_epo +1)+ \"/\"+str(EPOCHS))\n    for t,data in enumerate(tk):\n        images,labels = data\n        images,labels = images.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        logits,loss = model(images,labels)\n        loss.backward()\n        optimizer.step()\n        total_loss+= loss.item()\n        total_acc += calc_accuracy(logits,labels)\n        tk.set_postfix({'loss':'%6f'%float(total_loss / (t+1)),'acc':'%6f'%float(total_acc / (t+1))})\n    return total_loss/len(dataloader), total_acc/len(dataloader)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(model,dataloader,current_epo):\n\n    model.eval()\n    total_loss =0.0\n    total_acc =0.0\n    tk =tqdm(dataloader,desc = \"EPOCH\" + \"[val]\"+str(current_epo +1)+ \"/\"+str(EPOCHS))\n    for t,data in enumerate(tk):\n        images,labels = data\n        images,labels = images.to(DEVICE), labels.to(DEVICE)\n        logits,loss = model(images,labels)\n        total_loss+= loss.item()\n        total_acc += calc_accuracy(logits,labels)\n        tk.set_postfix({'loss':'%6f'%float(total_loss / (t+1)),'acc':'%6f'%float(total_acc / (t+1))})\n    return total_loss/len(dataloader), total_acc/len(dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(),lr = LR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_valid_loss = np.Inf\ntrain_losses = []\nvalid_losses = []\nfor i in range(EPOCHS):\n    train_loss,train_acc = train_fn(model,trainloader,optimizer,i)\n    valid_loss,valid_acc = eval_fn(model,validloader,i)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    if valid_loss < best_valid_loss:\n        torch.save(model.state_dict(),'best_model.pt')\n        print(\"Saved Model\")\n        best_valid_loss = valid_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_losses,'r')\nplt.plot(valid_losses,'b')\nplt.legend(['Training loss', 'Validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = valid_df['ClassId']\ny_true = np.asarray(y_true)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/working/best_model.pt'))\npredicted =[]\n\nwith torch.no_grad():\n    model.eval()\n    i = 0\n    for idx in range(valid_df.shape[0]):\n        image,label = validset[idx]\n        logits_ = model(image.to(DEVICE).unsqueeze(0))   #(c,h,w)\n        logits_ =nn.functional.softmax(logits_, dim =1)\n        logit_ = logits_.squeeze().cpu().detach().numpy()\n        pred_label = id2label[np.argmax(logit_)]\n        true_label = id2label[np.argmax(label)]\n        #print(\"predicted_label is:\",pred_label ,\"\\n\",\"Ground truth label is:\",true_label)\n        predicted.append(np.argmax(logit_))\n        \npredicted = np.asarray(predicted)      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix,ConfusionMatrixDisplay\n\nprint(accuracy_score(y_true,predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(labels, pred_labels, classes):\n    \n    fig = plt.figure(figsize = (18, 16));\n    ax = fig.add_subplot(1, 1, 1);\n    cm = confusion_matrix(labels, pred_labels);\n    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n    plt.xticks(rotation = 20)\n    \nlabels_arr = range(0, 43)\nplot_confusion_matrix(y_true, predicted, labels_arr)\n\nplt.savefig(\"confusion_matrix.png\", bbox_inches = 'tight', pad_inches=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(5,4,figsize=(50,75))\n\nfor i in range(20):\n    row = i // 4\n    col = i % 4\n    \n    img_path = path + valid_df.iloc[i].Path\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    axs[row, col].imshow(img)\n    title = \"Pred: %s,\\n Actual: %s\" % (id2label[predicted[i]], id2label[y_true[i]])\n    axs[row, col].set_title(title, fontsize=40)\n    axs[row, col].axis('off')\nplt.tight_layout()\n\nplt.savefig(\"predictions.png\", bbox_inches = 'tight', pad_inches=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}